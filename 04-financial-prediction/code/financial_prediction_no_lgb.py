#!/usr/bin/env python3
"""
Version simplifiÃ©e sans LightGBM pour Ã©viter les problÃ¨mes de compatibilitÃ©
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import xgboost as xgb
from catboost import CatBoostRegressor
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit
import warnings
warnings.filterwarnings('ignore')

# Chargement des donnÃ©es
print("ğŸ“Š Chargement des donnÃ©es...")
train_df = pd.read_csv('data/train.csv')
test_df = pd.read_csv('data/test.csv')

train_df['Dates'] = pd.to_datetime(train_df['Dates'])
test_df['Dates'] = pd.to_datetime(test_df['Dates'])

print(f"Train shape: {train_df.shape}")
print(f"Test shape: {test_df.shape}")

# Feature engineering simple
print("\nğŸ”§ Feature Engineering...")
for df in [train_df, test_df]:
    df['year'] = df['Dates'].dt.year
    df['month'] = df['Dates'].dt.month
    df['quarter'] = df['Dates'].dt.quarter
    df['day_of_year'] = df['Dates'].dt.dayofyear

# PrÃ©paration des donnÃ©es
feature_cols = [col for col in train_df.columns if col not in ['Dates', 'ToPredict']]
X_train = train_df[feature_cols]
y_train = train_df['ToPredict']
X_test = test_df[feature_cols]

# Normalisation
print("\nğŸ“ Normalisation des donnÃ©es...")
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ModÃ¨les
print("\nğŸ—ï¸ EntraÃ®nement des modÃ¨les...")

models = {
    'XGBoost': xgb.XGBRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42
    ),
    'CatBoost': CatBoostRegressor(
        iterations=500,
        learning_rate=0.05,
        depth=6,
        random_state=42,
        verbose=False
    ),
    'Ridge': Ridge(alpha=1.0, random_state=42)
}

# EntraÃ®nement et prÃ©dictions
predictions = {}

for name, model in models.items():
    print(f"  - EntraÃ®nement {name}...")
    model.fit(X_train_scaled, y_train)
    pred = model.predict(X_test_scaled)
    predictions[name] = pred
    print(f"    âœ… Moyenne: {pred.mean():.4f}, Std: {pred.std():.4f}")

# Ensemble par moyenne pondÃ©rÃ©e
print("\nğŸ¯ CrÃ©ation de l'ensemble...")
# Poids basÃ©s sur la performance habituelle
weights = {'XGBoost': 0.4, 'CatBoost': 0.4, 'Ridge': 0.2}
final_predictions = np.zeros(len(X_test))

for name, weight in weights.items():
    final_predictions += weight * predictions[name]

# CrÃ©ation du fichier de soumission
print("\nğŸ“ CrÃ©ation du fichier de soumission...")
submission = pd.DataFrame({
    'ID': test_df['Dates'].dt.strftime('%Y-%m-%d'),
    'ToPredict': final_predictions
})

submission.to_csv('submission_simple.csv', index=False)
print("âœ… Fichier crÃ©Ã©: submission_simple.csv")

# Statistiques
print("\nğŸ“Š Statistiques des prÃ©dictions:")
print(submission['ToPredict'].describe())

# Graphique
plt.figure(figsize=(12, 5))
plt.plot(test_df['Dates'], final_predictions)
plt.title('PrÃ©dictions finales')
plt.xlabel('Date')
plt.ylabel('Valeur prÃ©dite')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('predictions_simple.png')
plt.show()

print("\nâœ… TerminÃ©!")